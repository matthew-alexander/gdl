{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knob_weight = 0.5\n",
    "input = 2\n",
    "goal_prediction = .8\n",
    "\n",
    "step_amount = 0.001\n",
    "\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a form of gradient descent\n",
    "where we update the \"knob_weight\" with the \"direction\" and amount\n",
    "\n",
    "The key to learning is adjusting the weights in the correct *direction* and by the correct *amount* so that the **error** reduces to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Error: 0.04 Prediction: 1.0\n",
      "Iteration: 1 Error: 0.36 Prediction: 0.2\n",
      "Iteration: 2 Error: 3.24 Prediction: 2.6\n",
      "Iteration: 3 Error: 29.16 Prediction: -4.6\n",
      "Iteration: 4 Error: 262.44 Prediction: 17.0\n",
      "Iteration: 5 Error: 2361.96 Prediction: -47.8\n",
      "Iteration: 6 Error: 21257.64 Prediction: 146.6\n",
      "Iteration: 7 Error: 191318.76 Prediction: -436.6\n",
      "Iteration: 8 Error: 1721868.84 Prediction: 1313.0\n",
      "Iteration: 9 Error: 15496819.56 Prediction: -3935.8\n",
      "Iteration: 10 Error: 139471376.04 Prediction: 11810.6\n",
      "Iteration: 11 Error: 1255242384.36 Prediction: -35428.6\n",
      "Iteration: 12 Error: 11297181459.2 Prediction: 106289.0\n",
      "Iteration: 13 Error: 1.01674633133e+11 Prediction: -318863.8\n",
      "Iteration: 14 Error: 9.15071698198e+11 Prediction: 956594.6\n",
      "Iteration: 15 Error: 8.23564528379e+12 Prediction: -2869780.6\n",
      "Iteration: 16 Error: 7.41208075541e+13 Prediction: 8609345.0\n",
      "Iteration: 17 Error: 6.67087267987e+14 Prediction: -25828031.8\n",
      "Iteration: 18 Error: 6.00378541188e+15 Prediction: 77484098.6\n",
      "Iteration: 19 Error: 5.40340687069e+16 Prediction: -232452292.6\n",
      "Iteration: 20 Error: 4.86306618362e+17 Prediction: 697356881.0\n",
      "Iteration: 21 Error: 4.37675956526e+18 Prediction: -2092070639.8\n",
      "Iteration: 22 Error: 3.93908360873e+19 Prediction: 6276211922.6\n",
      "Iteration: 23 Error: 3.54517524786e+20 Prediction: -18828635764.6\n",
      "Iteration: 24 Error: 3.19065772307e+21 Prediction: 56485907297.0\n",
      "Iteration: 25 Error: 2.87159195077e+22 Prediction: -1.69457721888e+11\n",
      "Iteration: 26 Error: 2.58443275569e+23 Prediction: 5.08373165667e+11\n",
      "Iteration: 27 Error: 2.32598948012e+24 Prediction: -1.525119497e+12\n",
      "Iteration: 28 Error: 2.09339053211e+25 Prediction: 4.57535849099e+12\n",
      "Iteration: 29 Error: 1.8840514789e+26 Prediction: -1.3726075473e+13\n",
      "Iteration: 30 Error: 1.69564633101e+27 Prediction: 4.11782264189e+13\n",
      "Iteration: 31 Error: 1.52608169791e+28 Prediction: -1.23534679257e+14\n",
      "Iteration: 32 Error: 1.37347352812e+29 Prediction: 3.7060403777e+14\n",
      "Iteration: 33 Error: 1.23612617531e+30 Prediction: -1.11181211331e+15\n",
      "Iteration: 34 Error: 1.11251355777e+31 Prediction: 3.33543633993e+15\n",
      "Iteration: 35 Error: 1.001262202e+32 Prediction: -1.00063090198e+16\n",
      "Iteration: 36 Error: 9.01135981798e+32 Prediction: 3.00189270594e+16\n",
      "Iteration: 37 Error: 8.11022383618e+33 Prediction: -9.00567811782e+16\n",
      "Iteration: 38 Error: 7.29920145256e+34 Prediction: 2.70170343535e+17\n",
      "Iteration: 39 Error: 6.5692813073e+35 Prediction: -8.10511030604e+17\n",
      "Iteration: 40 Error: 5.91235317657e+36 Prediction: 2.43153309181e+18\n",
      "Iteration: 41 Error: 5.32111785892e+37 Prediction: -7.29459927543e+18\n",
      "Iteration: 42 Error: 4.78900607302e+38 Prediction: 2.18837978263e+19\n",
      "Iteration: 43 Error: 4.31010546572e+39 Prediction: -6.56513934789e+19\n",
      "Iteration: 44 Error: 3.87909491915e+40 Prediction: 1.96954180437e+20\n",
      "Iteration: 45 Error: 3.49118542724e+41 Prediction: -5.9086254131e+20\n",
      "Iteration: 46 Error: 3.14206688451e+42 Prediction: 1.77258762393e+21\n",
      "Iteration: 47 Error: 2.82786019606e+43 Prediction: -5.31776287179e+21\n",
      "Iteration: 48 Error: 2.54507417645e+44 Prediction: 1.59532886154e+22\n",
      "Iteration: 49 Error: 2.29056675881e+45 Prediction: -4.78598658461e+22\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(50):\n",
    "    \n",
    "    prediction = input * knob_weight\n",
    "    \n",
    "    error = (goal_prediction-prediction) ** 2 \n",
    "    \n",
    "    \n",
    "    derivative = (prediction - goal_prediction) * input\n",
    "\n",
    "    knob_weight = knob_weight - derivative\n",
    "    \n",
    "    if iteration % display_step == 0:\n",
    "        print(\"Iteration: \" + str(iteration) + \" Error: \" + str(error) + \" Prediction: \" + str(prediction))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The key concept: \n",
    "\n",
    "## \"Learning is adjusting our weight to reduce the error to zero\"\n",
    "\n",
    "First, our neural network is really just a bunch of **weights** and\n",
    "an **error** function. Our goal is to move the weights (in this case just one) so that our error goes\n",
    "to zero! How do we do this? Well, it turns out we can take the derivative between two variables\n",
    "in any function. When we do this, we learn how one changes when we change the other. We can\n",
    "then use this to modify each weight in the **direction** that leads us to the lowest error. How do we\n",
    "know this direction, it is always in the opposite of the value of our derivative. (p. 41)\n",
    "\n",
    "We are trying to figure out the direction and the\n",
    "amount to change our weight so that our error goes down. A derivative gives us the relationship\n",
    "between any two variables in a function. We use the derivative to determine the relationship be-\n",
    "tween any weight and the error. We then move our weight in the opposite direction of the deriva-\n",
    "tive to find the lowest weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key structure:\n",
    "* Inputs\n",
    "* weights\n",
    "* prediction\n",
    "* error\n",
    "* derivative -- the measure of the effect of the weight on the error\n",
    "* update the weight \n",
    "* loop (predict again) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives\n",
    "\n",
    "\n",
    "We can actually compute the slope (i.e. derivative) of the line for any value\n",
    "of knob_weight. We can then use this slope (derivative) to figure out which direction reduces\n",
    "our error! Even better, based on the steepness we can get at least some idea for how far away we\n",
    "are\n",
    "\n",
    "What is the difference between the error and the derivative of our error and knob_\n",
    "weight? **Well the error is just a measure of how much we missed. The derivative defines the real-\n",
    "tionship between each weight and how much we missed.** In other words, it tells how how much\n",
    "changing a weight contributed to the error\n",
    "\n",
    "We are trying to figure out the direction and the\n",
    "amount to change our weight so that our error goes down. A derivative gives us the relationship\n",
    "between any two variables in a function. We use the derivative to determine the relationship be-\n",
    "tween any weight and the error. We then move our weight in the opposite direction of the deriva-\n",
    "tive to find the lowest weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Divergence \n",
    "\n",
    "its pretty easy to break this -- just put 2 in as an input. What happens is that small changes to the knob cause huge changes in the prediction and lead to instability \n",
    "\n",
    "if we have a BIG input, then the prediction is VERY sensitive to changes in\n",
    "the weight (since prediction = input * knob_weight). \n",
    "\n",
    "* this is intersting cause  in the traffic signs thing -- and a reason why you would normalize\n",
    "\n",
    "The solution is to multiply the weight update by\n",
    "a fraction to make it smaller. In most cases, this involves multiplying our weight update by\n",
    "a single real-valued number between 0 and 1, known as alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Error: 0.04 Prediction: 1.0\n",
      "Iteration: 1 Error: 0.0144 Prediction: 0.92\n",
      "Iteration: 2 Error: 0.0052 Prediction: 0.872\n",
      "Iteration: 3 Error: 0.0019 Prediction: 0.8432\n",
      "Iteration: 4 Error: 0.0007 Prediction: 0.8259\n",
      "Iteration: 5 Error: 0.0002 Prediction: 0.8156\n",
      "Iteration: 6 Error: 0.0001 Prediction: 0.8093\n",
      "Iteration: 7 Error: 0.0 Prediction: 0.8056\n",
      "Iteration: 8 Error: 0.0 Prediction: 0.8034\n",
      "Iteration: 9 Error: 0.0 Prediction: 0.802\n",
      "Iteration: 10 Error: 0.0 Prediction: 0.8012\n",
      "Iteration: 11 Error: 0.0 Prediction: 0.8007\n",
      "Iteration: 12 Error: 0.0 Prediction: 0.8004\n",
      "Iteration: 13 Error: 0.0 Prediction: 0.8003\n",
      "Iteration: 14 Error: 0.0 Prediction: 0.8002\n",
      "Iteration: 15 Error: 0.0 Prediction: 0.8001\n",
      "Iteration: 16 Error: 0.0 Prediction: 0.8001\n",
      "Iteration: 17 Error: 0.0 Prediction: 0.8\n",
      "Iteration: 18 Error: 0.0 Prediction: 0.8\n",
      "Iteration: 19 Error: 0.0 Prediction: 0.8\n"
     ]
    }
   ],
   "source": [
    "# adding alpha to limit the derivative so it doesnt over shoot\n",
    "knob_weight = 0.5\n",
    "input = 2\n",
    "goal_prediction = .8\n",
    "step_amount = 0.001\n",
    "display_step = 1\n",
    "alpha = .1\n",
    "\n",
    "for iteration in range(20):\n",
    "    prediction = input * knob_weight\n",
    "    error = (goal_prediction-prediction) ** 2 \n",
    "    derivative = (prediction - goal_prediction) * input\n",
    "    knob_weight = knob_weight - alpha * derivative\n",
    "    \n",
    "    if iteration % display_step == 0:\n",
    "        print(\"Iteration: \" + str(iteration) + \" Error: \" + str(round(error,4)) + \n",
    "              \" Prediction: \" + str(round(prediction,4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
